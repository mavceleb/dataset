<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        /* Including Monsterrat font */
        @font-face {
            font-family: 'montserrat_regular';
            src: url('./static/fonts/Montserrat/static/Montserrat-Regular.ttf') format('truetype');
        }

        @font-face {
            font-family: 'montserrat_medium';
            src: url('./static/fonts/Montserrat/static/Montserrat-Medium.ttf') format('truetype');
        }

        @font-face {
            font-family: 'montserrat_bold';
            src: url('./static/fonts/Montserrat/static/Montserrat-Bold.ttf') format('truetype');
        }

        @font-face {
            font-family: 'montserrat_lightItalic';
            src: url('./static/fonts/Montserrat/static/Montserrat-LightItalic.ttf') format('truetype');
        }

        /* //////////////////////////////////////////////////////////////////////// */


        /* Defining base properties */
        :root {
            --main-color: rgba(35, 35, 37, 1); /* Define a variable for the main color */
            --secondary-color: rgba(249, 249, 249, 1); /* Define a variable for the secondary color */
        }

        html{
            scroll-behavior: smooth;
        }

        body {
            display: flex;
            flex-direction: column;
            align-items: center;
            margin: 0;
            font-family: montserrat_regular;
            color: black;
            font-size: 16px;
            font-family: montserrat_regular;
            text-align: justify;
        }
        /* //////////////////////////////////////////////////////////////////////// */


        /* Navbar */
        nav {
            position: fixed;
            z-index: 100;
            background-color: var(--main-color);
            height: 10vh; /* 10% of the vertical height */
            width: 100%;
            display: flex;
            justify-content: space-evenly; /* Align items to the right */
            align-items: center;
            /* padding: 0 20px; */
            font-family: montserrat_medium;
            font-size: 20px;
        }

        nav a {
            text-decoration: none;
            color: var(--secondary-color);
            margin-right: 2vw; /* Adjust the margin as needed */
        }

        nav a:hover{
            color: #e74c3c; /* Change the color on hover */
        }
        /* //////////////////////////////////////////////////////////////////// */


        /* Body container */
        .body-container{
            width: 60%;
            background-color: var(--secondary-color);
        }
        /* /////////////////////////////////////////////////////////////////// */


        /* Banner */
        .banner-container{
            display: flex;
            justify-content: center;
            align-items: center;
            width: 100%;
            height: 45vh;
            background-image: url(./static/images/Banner2.png);
            background-size: contain;
            background-position: center;
            background-repeat: no-repeat;
            background-position: top;
            margin-top: 10vh;
        }


        .card-container{
            display: flex;
            width: 350px;
            background-color: var(--secondary-color);
            opacity: 0.85; /* Set the desired opacity value */
            height: 80px;
            justify-content: center;
            align-items: center;
            text-align: center;
            font-size: 26px;
            font-family: montserrat_medium;
            border-radius: 10px;
            box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.6); /* Set the box shadow */
            transition: transform 0.3s;
        }

        .card-container:hover{
            transform: scale(1.02);
        }
        /* ///////////////////////////////////////////////////////////////////// */


        /* Description data */
        .descriptions{
            padding: 0 40px;
        }

        .description-headings{
            font-family: montserrat_medium;
            font-size: 24px;
            margin-top: 8vh;
        }

        .figures{
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            font-family: montserrat_lightItalic;
            font-size: 12px;
            text-align: center;
        }

        .figures img{
            width: 80%;
        }
        /* ////////////////////////////////////////////////////////////////////// */


        .footer{
            margin-top: 10vh;
            width: 100%;
            height: 5vh;
            background-color: var(--main-color);
        }


        @media (max-width: 900px) {
            .body-container{
                width: 100%;
            }

            .banner-container{
                height: 30vh;
            }
        }
    </style>
</head>
<body>

    <!-- Navbar -->
    <nav>
        <div>
            <a href="./index.html">Home</a>
            <a href="#about">About</a>
            <a href="#baseline">Baseline</a>
            <a href="#evaluation">Evaluation</a>
            <a href="#dataset">Dataset</a>
            <a href="#registration">Registration</a>
            <a href="#organizers">Organizers</a>
            
        </div>
    </nav>
    <!-- //////////////////////////////////////////////////////////////////////// -->

    <!-- banner -->
    <div class="body-container">
        <div class="banner-container">
            <div class="card-container">
                FAME Challenge 2024
            </div>
        </div>
        <!-- //////////////////////////////////////////////////////////////////////// -->

        <!-- Introduction -->
        <div class="descriptions">
            <p>
                The face and voice of a person have unique characteristics and they are well used as biometric 
                measures for person authentication either as a unimodal or multimodal. A strong correlation has 
                been found between face and voice of a person, which has attracted significant research interest. 
                Though previous works have established association between faces and voices, none of these approaches 
                investigated the effect of multiple languages on this task. As half of the population of world is 
                bilingual and we are more often communicating in multilingual scenarios [10], therefore, it is essential 
                to investigate the effect of language for associating faces with the voices. Thus, the goal of the 
                <b>Face-voice Association in Multilingual Environments (FAME)</b> challenge is to analyze the impact of multiple 
                languages on face-voice association task.
            </p>
        </div>

        <!-- About Dataset -->
        <div class="descriptions" id="about">
            <p class="description-headings">ABOUT DATASET</p>
            <p>
                Our dataset comprises of two versions, MAV-CELEB v1 and MAV-CELEB v2 both containing 
                different (non-inclusive) speaker identities. The v1 contains audio visual data of speakers
                 with Urdu and English languages while the v2 contains speakers with Hindi and English languages.
            </p>
            <ul>
                <li>Facial images</li>
                <li>Voice recordings</li>
                <ul>
                    <li>Urdu (v1 only)</li>
                    <li>English (v1 and v2)</li>
                    <li>Hindi (v2 only)</li>
                </ul>
            </ul>
            <p>The data is available in two formats:</p>
            <ul>
                <li>Raw Images and audio file.</li>
                <li>CSV files of image and audio features extracted through a pretrained
                     feature extraction model (utterance level aggregator for voice and vggface for images).</li>
            </ul>
        </div>

        <!-- Baseline Model -->
        <div class="descriptions" id="baseline">
            <p class="description-headings">BASELINE MODEL</p>
            <p>
                We provide a baseline model that has been trained on extracted features for facial and 
                audio data (vggface for images and utterance level aggregator for voices). Our two branch network 
                learn a fusion embedding and compares the affect of different loss formulations on the test set.
                <br> <br>
                Link to the paper: 
                <a href="https://ieeexplore.ieee.org/abstract/document/9747704/">
                    Fusion and Orthogonal Projection for Improved Face-Voice Association
                </a>
            </p>
        </div>
        <div class="figures">
            <img src="./static/images/methodology.png">
            <p>Figure 1: Diagram showing our methodology.</p>
        </div>
        <div class="figures">
            <img src="./static/images/results.png" style="width: 50%;">
            <p style="width: 50%;">Figure 2: Cross-modal verification results for our loss and other losses under two configurations 
                and two error metrics.</p>
        </div>

        <!-- Evaluation Metrics -->
        <div class="descriptions" id="evaluation">
            <p class="description-headings">EVALUATION METRICS</p>
            <p>
                The training and validation sets will be shared to the participants on the first day of the progress 
                phase, which they can use to build their systems. A pretrained model will also be shared during this 
                period. The evaluation set without the keys will be shared on the first day of the evaluation phase, 
                which the participants can use to test using their trained models that they developed during the progress phase.
            </p>
            <p>We measure the results on metrics:</p>
            <ul>
                <li>AUC (Area under the ROC Curve)</li>
                <li>EER (Equal Error Rate)</li>
            </ul>
            <p>on both seen-heard and unseen-unheard cases.</p>
        </div>

        <!-- Dataset -->
        <div class="descriptions" id="dataset">
            <p class="description-headings">DATASET</p>
            <p>The dataset is available on the following links:</p>
            <ul>
                <li>MAV-CELEB v1</li>
                <ul>
                    <li>Raw files: <span><a href="https://github.com/mavceleb/dataset">https://github.com/mavceleb/dataset</a></span></li>
                    <li>CSV files: <span><a href="https://github.com/mavceleb/dataset">https://github.com/mavceleb/dataset</a></span></li>
                </ul>
                <li>MAV-CELEB v2</li>
                <ul>
                    <li>Raw files: <span><a href="https://github.com/mavceleb/dataset">https://github.com/mavceleb/dataset</a></span></li>
                    <li>CSV files: <span><a href="https://github.com/mavceleb/dataset">https://github.com/mavceleb/dataset</a></span></li>
                </ul>
            </ul>
            <p>on both seen-heard and unseen-unheard cases.</p>
        </div>

        <!-- Registration -->
        <div class="descriptions" id="registration">
            <p class="description-headings">REGISTRATION</p>
            <p>We welcome participants to apply for the “FAME Challenge 2023” by expressing their interest via email at 
                <span><a href="mailto:mavceleb@gmail.com">mavceleb@gmail.com</a></span> 
                through their institutional emails with the subject “REGISTRATION FOR FAME CHALLENGE 2023”.</p>
        </div>

        <!-- Organizers -->
        <div class="descriptions" id="organizers">
            <p class="description-headings">ORGANIZERS</p>
            <p>
                Muhammad Saad Saeed - <span  style="font-size: 12px;">Swarm Robotics Lab (SRL)-NCRA, University of Engineering and Technology Taxila</span> <br>
                Shah Nawaz - <span  style="font-size: 12px;">Johannes Kepler University Linz</span> <br>
                Muhammad Salman Tahir - <span  style="font-size: 12px;">Swarm Robotics Lab (SRL)-NCRA, University of Engineering and Technology Taxila</span> <br>
                Rohan Kumar Das - <span  style="font-size: 12px;">Fortemedia Singapore, Singapore</span> <br>
                Muhammad Zaigham Zaheer - <span  style="font-size: 12px;">Mohamed bin Zayed University of Artificial Intelligence</span> <br>
                Marta Moscati - <span  style="font-size: 12px;">Institute of Computational Perception, Johannes Kepler University Linz, Austria</span> <br>
                Markus Schedl - <span  style="font-size: 12px;">Institute of Computational Perception, Johannes Kepler University Linz, Austria | Human-centered AI Group, AI Lab, Linz Institute of Technology, Austria</span> <br>
                Muhammad Haris Khan - <span  style="font-size: 12px;">Mohamed bin Zayed University of Artificial Intelligence</span> <br>
                Karthik Nandakumar - <span  style="font-size: 12px;">Mohamed bin Zayed University of Artificial Intelligence</span> <br>
                Muhammad Haroon Yousaf - <span  style="font-size: 12px;">Swarm Robotics Lab (SRL)-NCRA, University of Engineering and Technology Taxila</span> <br>
                </p>
        </div>



        <!-- footer -->
        <div class="footer">

        </div>
    </div>
    

</body>
</html>